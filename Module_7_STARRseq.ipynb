{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python in genomic analysis - a case study\n",
    "\n",
    "1. Read the paper (Optional if you are looking at your own data)\n",
    "2. Formulate the question\n",
    "3. Find the data\n",
    "4. Obtain, process\n",
    "5. Analyze!\n",
    "\n",
    "## Paper: Hormone-Responsive Enhancer-Activity Maps Reveal Predictive Motifs, Indirect Repression, and Targeting of Closed Chromatin\n",
    "\n",
    "### Questions: \n",
    "1. Where are the ecdysone-induced enhancers in chromosome 3L?\n",
    "2. What transcription factors may bind at these enhancers?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the data?\n",
    "\n",
    "#### This happens behind the scenes for this class to save time, but I wanted to share the whole process so you are aware of how you could do this by yourself.\n",
    "\n",
    "1. Get the \"reads\" as fastq files<br><br>\n",
    "`\n",
    "fastq-dump SRR1204764\n",
    "fastq-dump SRR1204762\n",
    "`\n",
    "<br><br>\n",
    "2. Align the reads to the genome<br><br>\n",
    "`\n",
    "bowtie2 -x /beevol/home/srinivas/lib/bowtie2/dm6/genome -q SRR1204764.fastq --no-unal -p 10 >  w_ecd.sam\n",
    "bowtie2 -x /beevol/home/srinivas/lib/bowtie2/dm6/genome -q SRR1204762.fastq --no-unal -p 10 >  wo_ecd.sam\n",
    "`\n",
    "<br><br>\n",
    "3. Convert the sam to bam (binary compressed format that will be read by bedtools)<br><br>\n",
    "`\n",
    "samtools view -Sb w_ecd.sam > w_ecd.bam\n",
    "samtools view -Sb wo_ecd.sam > wo_ecd.bam\n",
    "`\n",
    "<br><br>\n",
    "\n",
    "4. Convert bam to bed (bed file will have one read per line, a human readable form)<br><br>\n",
    "`\n",
    "bedtools bamtobed -i w_ecd.bam > w_ecd.bed\n",
    "bedtools bamtobed -i wo_ecd.bam > wo_ecd.bed\n",
    "`\n",
    "<br><br>\n",
    "\n",
    "5. Convert bed to wig (we collapse the reads into a wig file)<br><br>\n",
    "\n",
    "`123456789`<br>\n",
    "`----_____`<br>\n",
    "`___----__`<br>\n",
    "`_____----`<br>\n",
    "`______---`<br>\n",
    "`______---`<br>\n",
    "`111212433`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readwig (inFile):\n",
    "  wig=open(inFile, 'r' )\n",
    "  val={}\n",
    "  for line in wig:\n",
    "    lineL = line.split()\n",
    "    if \"chr\" in lineL[1]:\n",
    "      cj=lineL[1]\n",
    "      chrom=cj[9:]\n",
    "      print(chrom)\n",
    "      val.setdefault(chrom,{})\n",
    "    elif \"rack\" not in line:\n",
    "      pos=int(lineL[0])\n",
    "      val[chrom][pos] = float(lineL[1])\n",
    "  return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_ecd = readwig('3L.w_ecd.wig')\n",
    "wo_ecd = readwig('3L.wo_ecd.wig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "subset_w_ecd = []\n",
    "for i in range(17950953-30000,17950953+30000):\n",
    "    if i in w_ecd['3L']:\n",
    "        subset_w_ecd.append(w_ecd['3L'][i])\n",
    "ns_w_ecd = np.array(subset_w_ecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ns_w_ecd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from numpy import pi\n",
    "\n",
    "x = np.linspace( 0, 6*pi, 600 )\n",
    "f = np.sin(x)\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html\n",
    "\n",
    "peaks, _ = find_peaks(f, height=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x,f)\n",
    "plt.plot(x[peaks], f[peaks], \"ro\")\n",
    "plt.ylim(-1.1,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.arange(0,len(ns_w_ecd))\n",
    "peaks, _ = find_peaks(ns_w_ecd) \n",
    "#peaks, _ = find_peaks(ns_w_ecd, height=ns_w_ecd.mean()) \n",
    "#peaks, _ = find_peaks(ns_w_ecd, height=ns_w_ecd.mean(),distance=10) \n",
    "#peaks, _ = find_peaks(ns_w_ecd, height=4*smooth_ar.std()+smooth_ar.mean())\n",
    "#our unit is 10 bp, so distance of 10 is highest peak within 100 bp\n",
    "plt.plot(ns_w_ecd)\n",
    "plt.plot(indices[peaks],ns_w_ecd[peaks], \"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Too rough so many local maxima. Let us try to smooth this distribution. We will use Savitsky Golay filter.\n",
    "# https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter\n",
    "# https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.signal.savgol_filter.html\n",
    "from scipy.signal import savgol_filter\n",
    "smooth_ar = savgol_filter(ns_w_ecd,9,1)\n",
    "peaks, _ = find_peaks(smooth_ar, height=3*smooth_ar.std()+smooth_ar.mean(), distance=10)\n",
    "#plt.plot(ns_w_ecd)\n",
    "plt.plot(smooth_ar,)\n",
    "plt.plot(indices[peaks],smooth_ar[peaks], \"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let us apply this to the whole chromosome\n",
    "\n",
    "temp_list = [] #Values\n",
    "pos_list = [] #Chromosome positions\n",
    "\n",
    "for i in sorted(w_ecd['3L'].keys()):\n",
    "    temp_list.append(w_ecd['3L'][i])\n",
    "    pos_list.append(i)\n",
    "\n",
    "chrom_array = np.array(temp_list)\n",
    "\n",
    "smooth_ar = savgol_filter(chrom_array,9,1)\n",
    "peaks_ecd, _ = find_peaks(smooth_ar, height=4*smooth_ar.std()+smooth_ar.mean(), distance=10)\n",
    "len(peaks_ecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now for the non ecdysone treated sample\n",
    "\n",
    "temp_list = []\n",
    "pos_list_wo = []\n",
    "\n",
    "for i in sorted(wo_ecd['3L'].keys()):\n",
    "    temp_list.append(wo_ecd['3L'][i])\n",
    "    pos_list_wo.append(i)\n",
    "\n",
    "chrom_array_wo = np.array(temp_list)\n",
    "\n",
    "smooth_ar_wo = savgol_filter(chrom_array_wo,9,1)\n",
    "peaks_wo_ecd, _ = find_peaks(smooth_ar_wo, height=4*smooth_ar_wo.std()+smooth_ar_wo.mean(), distance=10)\n",
    "len(peaks_wo_ecd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the peaks make sense?\n",
    "\n",
    "1. Let us first understand how to trace back the genomic location from the peak<br><br>\n",
    "\n",
    "`Indices  :  0  1  2  3  4  5  6  7  8`<br>\n",
    "`Positions: 22 23 24 25 26 27 28 29 30`<br>\n",
    "`maxima   :           *        *      `<br><br>\n",
    "`peak_list : 3,6`<br><br>\n",
    "`peak_list[0] = 3`<br><br>\n",
    "`positions[peak_list[0]] = 25`\n",
    "<br><br>Now we can ask if the signal around the peak position is high.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spit out a random peak\n",
    "\n",
    "rand_index = int(np.random.rand()*len(peaks_ecd)-1)\n",
    "print(rand_index)\n",
    "print(peaks_ecd[rand_index])\n",
    "peak_val = pos_list[peaks_ecd[rand_index]]\n",
    "print(peak_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_w_ecd = []\n",
    "location = []\n",
    "for i in range(peak_val-2000,peak_val+2000):\n",
    "    if i in w_ecd['3L']:\n",
    "        subset_w_ecd.append(w_ecd['3L'][i])\n",
    "    else:\n",
    "        subset_w_ecd.append(0)\n",
    "    location.append(i-peak_val)\n",
    "ns_w_ecd = np.array(subset_w_ecd)\n",
    "plt.plot(location,ns_w_ecd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't want to see one peak at a time. How about an average profile of all peaks?\n",
    "\n",
    "`\n",
    "position: -2000 -1990 ....... 0  ....... 1990 2000\n",
    "peak 1  :    x1    x2 ....... xn .......   xm   xp\n",
    "peak 2  :    y1    y2 ....... yn .......   ym   yp\n",
    ".\n",
    ".\n",
    ".\n",
    ".`<br>\n",
    "`peak j  :    z1    z2 ....... zn .......   zm   zp`<br>\n",
    "`--------------------------------------------------`<br>\n",
    "`Average :    a1    a2 ....... an .......   am   ap`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "peak_score_w_ecd = {}\n",
    "\n",
    "fh = open(\"py_peaks_w_ecd.bed\",\"w\")\n",
    "ave_vals = {}\n",
    "location = []\n",
    "for p in peaks_ecd:\n",
    "    peak_pos = pos_list[p]\n",
    "    temp_str = \"chr3L\\t\" + str(peak_pos-250) + \"\\t\" + str(peak_pos+250) + \"\\t\" + str(p) + \"\\n\"\n",
    "    fh.write(temp_str)\n",
    "    for i in range(peak_pos-2000,peak_pos+2000):\n",
    "        if i in w_ecd['3L']:\n",
    "            ave_vals.setdefault('val',{})\n",
    "            if i-peak_val in ave_vals:\n",
    "                ave_vals['val'][i-peak_pos] += w_ecd['3L'][i]\n",
    "            else:\n",
    "                ave_vals['val'][i-peak_pos] = w_ecd['3L'][i]\n",
    "    score=0\n",
    "    key=\"chr3L:\" + str(peak_pos-250) + \"-\" + str(peak_pos+250)\n",
    "    for i in range(peak_pos-100,peak_pos+100):\n",
    "        if i in w_ecd['3L']:\n",
    "            score+=w_ecd['3L'][i]\n",
    "        peak_score_w_ecd[key] = score/20\n",
    "\n",
    "fh.close()\n",
    "df_ave_vals = pd.DataFrame(ave_vals)\n",
    "df_ave_vals['val'] /= len(peaks_ecd)\n",
    "plt.plot(df_ave_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh = open(\"py_peaks_wo_ecd.bed\",\"w\")\n",
    "ave_vals_wo = {}\n",
    "location_wo = []\n",
    "for p in peaks_wo_ecd:\n",
    "    peak_pos = pos_list_wo[p]\n",
    "    temp_str = \"chr3L\\t\" + str(peak_pos-250) + \"\\t\" + str(peak_pos+250) + \"\\t\" + str(p) + \"\\n\"\n",
    "    fh.write(temp_str)\n",
    "    for i in range(peak_pos-2000,peak_pos+2000):\n",
    "        if i in wo_ecd['3L']:\n",
    "            ave_vals_wo.setdefault('val',{})\n",
    "            if i-peak_val in ave_vals_wo:\n",
    "                ave_vals_wo['val'][i-peak_pos] += wo_ecd['3L'][i]\n",
    "            else:\n",
    "                ave_vals_wo['val'][i-peak_pos]  = wo_ecd['3L'][i]\n",
    "\n",
    "fh.close()\n",
    "df_ave_vals = pd.DataFrame(ave_vals_wo)\n",
    "df_ave_vals['val'] /= len(peaks_wo_ecd)\n",
    "plt.plot(df_ave_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What Transcription Factor motifs underlie enhancer peaks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pybedtools \n",
    "\n",
    "enhancers_w_ecd = pybedtools.BedTool('py_peaks_w_ecd.bed')\n",
    "enhancers_wo_ecd = pybedtools.BedTool('py_peaks_wo_ecd.bed')\n",
    "\n",
    "activated_enhancers = enhancers_w_ecd - enhancers_wo_ecd #Enhancers unique to Ecdysone treatment\n",
    "\n",
    "print(activated_enhancers.count())\n",
    "\n",
    "g = activated_enhancers.sequence(fi='3L.fa')\n",
    "\n",
    "#g.seqfn\n",
    "\n",
    "fo = open('w_ecd_peaks.fa', 'w')\n",
    "fo.write(open(g.seqfn).read())\n",
    "\n",
    "g = enhancers_wo_ecd.sequence(fi='3L.fa')\n",
    "\n",
    "fo = open('wo_ecd_peaks.fa', 'w')\n",
    "fo.write(open(g.seqfn).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_ecd_motifs = pd.read_csv('fimo_w_ecd.txt',sep='\\t')\n",
    "w_ecd_motifs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wo_ecd_motifs = pd.read_csv('fimo_wo_ecd.txt',sep='\\t')\n",
    "wo_ecd_motifs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_w_ecd = (w_ecd_motifs.groupby('motif_alt_id').count()/len(w_ecd_motifs)).iloc[:,0:1]\n",
    "norm_wo_ecd = (wo_ecd_motifs.groupby('motif_alt_id').count()/len(wo_ecd_motifs)).iloc[:,0:1]\n",
    "print(norm_w_ecd.head())\n",
    "print(norm_wo_ecd.head())\n",
    "mergeddf = pd.merge(norm_w_ecd, norm_wo_ecd, how = 'left', on = 'motif_alt_id')\n",
    "mergeddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio_w  = mergeddf['# motif_id_x']\n",
    "ratio_wo = mergeddf['# motif_id_y']\n",
    "\n",
    "Enrichment = (ratio_w / ratio_wo)\n",
    "#print(Enrichment)\n",
    "\n",
    "#Now add these values as a new column\n",
    "newdf = mergeddf.assign(Enrichment = Enrichment)\n",
    "print(newdf.sort_values(by='Enrichment',ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peak_score_w_ecd[w_ecd_motifs.iloc[0]['sequence_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with_score = pd.DataFrame()\n",
    "for i in newdf.sort_values(by='Enrichment',ascending=False).head(5).index.values:\n",
    "    new_df = w_ecd_motifs.query(\"motif_alt_id == '{0}'\".format(i)).iloc[:,1:3]\n",
    "    #print(new_df.head(1))\n",
    "    score_col = []\n",
    "    for index, row in new_df.iterrows():\n",
    "        score_col.append(peak_score_w_ecd[row['sequence_name']])\n",
    "    new_df = new_df.assign(score_col = score_col)\n",
    "    with_score = with_score.append(new_df)\n",
    "with_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(data = with_score, x = 'motif_alt_id', y = 'score_col')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
